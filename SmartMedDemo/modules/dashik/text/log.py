mistakes = '''
Матрица ошибок – это показатель успешности классификации для 2 классов. Это таблица с 4 различными комбинациями сочетаний прогнозируемых и фактических значений.\n
TP (True Positives) — верно классифицированные положительные примеры.

TN (True Negatives) — верно классифицированные отрицательные примеры.

FN (False Negatives) — положительные примеры, классифицированные как отрицательные.

FP (False Positives) — отрицательные примеры, классифицированные как положительные.
'''

roc = '''
ROC-кривая показывает зависимость количества верно классифицированных положительных примеров от количества неверно классифицированных отрицательных примеров при различных значениях порога отсечения. Чем ближе кривая к верхнему левому углу, тем выше предсказательная способность модели.
		'''

prognos = '''
Чувствительность алгоритма совпадает с долей положительных объектов, правильно классифицированных алгоритмом\n
Специфичность алгоритма определяется как доля отрицательных объектов, правильно классифицированных алгоритмом.\n
Модель с высокой чувствительностью чаще дает истинный результат при наличии положительного исхода (хорошо обнаруживает положительные примеры). Наоборот, модель с высокой специфичностью чаще дает истинный результат при наличии отрицательного исхода (хорошо обнаруживает отрицательные примеры).\n
AUC (Area Under Curve) – численный показатель площади под ROC кривой.\n
Доля верных ответов – доля (процент) объектов, на которых алгоритм выдал правильные ответы.
        '''

crit = '''
b - коэффициенты уравнения регрессии.  
St.Error b - стандартная ошибка коэффициентов уравнения регрессии.  
t-критерий - значение t-статистики, определяющей статистическую значимость каждого коэффициента.   
p-value - вероятность того, что коэффициент не значимый. Если значение меньше 0.05, то коэффициент следует признать значимым.  
		'''
quality = '''
R2 – псевдо-R-квадрат Макфаддена. Данный коэффициент численно выражает долю вариации зависимой переменной, объясненную с помощью регрессионного уравнения. Чем ближе R2 к 1, тем лучше регрессия описывает зависимость между объясняющими и зависимой переменными.  \n
df - степени свободы. Число степеней свободы объясненной дисперсии k1 равно количеству объясняющих переменных. Число степеней свободы необъясненной дисперсии k2 = N-k-1, где N-количество экспериментальных точек, k-количество объясняющих переменных. \n
Способы оценки сложностей: AIC (критерий Акаике) и BIC (Байесовский информационный критерий).\n
X2 -  статистика хи-квадрат отношения правдоподобия.\n
p - Вероятность хи-квадрат получить статистику отношения логарифмического правдоподобия больше, чем llr. llr имеет распределение хи-квадрат со степенями свободы df_model .

        '''
oprlog = '''
Логистическая регрессия — это разновидность множественной регрессии, общее назначение которой состоит в анализе связи между несколькими независимыми переменными (называемыми также регрессорами или предикторами) и зависимой переменной. Бинарная логистическая регрессия применяется в случае, когда зависимая переменная может принимать только два значения
'''
oprlin = '''

'''